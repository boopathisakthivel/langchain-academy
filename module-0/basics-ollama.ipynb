{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! This course will use [ChatOllama](https://python.langchain.com/docs/integrations/chat/ollama/) because it can be tested in local with all available models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_ollama langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a useful how-to for all the things that you can do with chat models, but we'll show a few highlights below. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-ollama` package. With this, we can instantiate our `ChatOllama` model object. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llama_chat = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-15T07:59:52.446773865Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3508678641, 'load_duration': 41883190, 'prompt_eval_count': 27, 'prompt_eval_duration': 408000000, 'eval_count': 25, 'eval_duration': 3057000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-ba091649-e258-4cbe-8017-82191ad6b067-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "llama_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-15T07:59:55.969126381Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3509299226, 'load_duration': 36898272, 'prompt_eval_count': 27, 'prompt_eval_duration': 241000000, 'eval_count': 25, 'eval_duration': 3230000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f8280320-6f80-409c-8453-8db51b793366-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks. \n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008bc61c-898b-4b6f-ab02-7237802e8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is Google?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Google | History & Facts; Products & Services | Britannica Money',\n",
       "  'url': 'https://www.britannica.com/money/Google-Inc',\n",
       "  'content': 'Google | History & Facts; Products & Services | Britannica Money Google is an American search engine company, founded in 1998 by Sergey Brin and Larry Page. Since 2015, Google has been a subsidiary of the holding company Alphabet, Inc. More than 70% of worldwide online search requests are handled by Google, placing it at the heart of most Internet users’ experience. Two years later the company responded to the explosive growth of the mobile applications market with a $750 million deal to acquire the mobile advertising network AdMob. All of these purchases were part of Google’s effort to expand from its search engine business into advertising by combining the various firms’ databases of information in order to tailor ads to consumers’ individual preferences.',\n",
       "  'score': 0.85967577},\n",
       " {'title': 'Google - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Google',\n",
       "  'content': 'Google is also part of Project Nimbus, a $1.2 billion deal in which the technology companies Google and Amazon will provide Israel and its military with artificial intelligence, machine learning, and other cloud computing services, including building local cloud sites that will \"keep information within Israel\\'s borders under strict security guidelines.\"[374][375][376] The contract has been criticized by shareholders and employees over concerns that the project could lead to human rights abuses against Palestinians, in the context of the Israeli–Palestinian conflict and the disputed status of Palestinian territories.[377][378] Ariel Koren, a former marketing manager for Google\\'s educational products and an outspoken critic of the project, wrote that Google \"systematically silences Palestinian, Jewish, Arab and Muslim voices concerned about Google\\'s complicity in violations of Palestinian human rights—to the point of formally retaliating against workers and creating an environment of fear\",  and said she was retaliated against for organizing against the project.[374][379]',\n",
       "  'score': 0.4892356},\n",
       " {'title': 'Google - About Google, Our Culture & Company News',\n",
       "  'url': 'https://about.google/',\n",
       "  'content': 'Google - About Google, Our Culture & Company News Google in the U.S. Products Our mission is to organize the world’s information and make it universally accessible and useful. Gemini 2.0: Our newest, most capable AI model yet Make life easier with a little help from our products View all our products Get product support [![Image 2: The latest Pixel phones](https://lh3.googleusercontent.com/CMeutwvkARWLCyrjSLBqp0KSCGYBZoL7lYkoqLYS-utC81JRLRUwMvdDcNypJ_p7iSAHRTvZX7G6tVaXRNCqT6QlNbP3E9mSEvwmRhTNMV-YQdR2J4af=w600-l90-sg-rj-c0xffffff) #### Experience Google AI and amazing photography made simple Explore the full Pixel 9 lineup](https://store.google.com/ideas/google-pixel-phones/?utm_source=about&utm_medium=google_oo&utm_campaign=GS108064&utm_term=homepage) Resources Brand Resource Center Help center Press resources Accessibility Crisis response Google.org Google Health Grow with Google Research and technology Google AI Google Cloud Google DeepMind Google for Developers Google Labs Google Research Safety Center Supplier responsibility Transparency Center Transparency report Help Terms',\n",
       "  'score': 0.3787583}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a498ac-d740-4504-a83f-ac81ee1c3e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aae271-a00c-453c-a235-2f869820cfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
